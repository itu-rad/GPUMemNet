# GPUMemNet: GPU Memory estimator and Neural Network training dataset
<p align="center">
  <img src="image/logo_with_background.png" alt="Alt Text" width="200"/>
</p>

This repository keeps all the artifact on our work on building an Deep Learning-based GPU memory estimator for deep learning training tasks. For this purpose, data is the integral part. 

So, first, we built the scripts required for producing different deep learning training tasks configurations randomly and monitoring the GPUs while training is the first step in this journey. 

After getting the raw data, cleaning the data is the next step as the corresponding scripts can be found as well.

Then we have the data, which we can actually start and analyze and train some models on them.

Finally analyzing the datasets and producing insights based data, and training models, and trying different approaches is the next step.







## Visualization, Analysis, and Training Notebooks


## Related Work

## Overheads of the parser and 

## Vision
In the discussion section of our paper, we draw the roadmap on how contributors can contribute. As it is an AI-based estimator, the potential contributions and improvements to the current study can come from more data points, data points from different GPU models, with broader range of arguments, and also innovations on how to view the GPU memory estimation.

## Requirements
Using the notebooks, they install and include the required packages.
- PyTorch
- Torch summary
- Pandas
- Numpy